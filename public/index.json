[{"content":"简介 colly 是用 Go 语言编写的功能强大的爬虫框架。它提供简洁的 API，拥有强劲的性能，可以自动处理 cookie\u0026amp;session，还有提供灵活的扩展机制。\n快速使用 安装 colly 库：\n1 $ go get -u github.com/gocolly/colly/v2 示例：爬取百度首页左上角链接\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gocolly/colly/v2\u0026#34; \u0026#34;testing\u0026#34; ) func TestCrawl(t *testing.T) { c := colly.NewCollector( colly.AllowedDomains(\u0026#34;www.baidu.com\u0026#34;), ) c.OnHTML(\u0026#34;#s-top-left a\u0026#34;, func(e *colly.HTMLElement) { fmt.Println(e.Text) }) c.Visit(\u0026#34;https://www.baidu.com/\u0026#34;) } colly 使用流程：\n调用 colly.newCollector() 创建一个类型为 *colly.Collector 的爬虫对象。由于每隔网页都有很多指向其它网页的链接。如果不加限制的话，运行可能永远不会停止。所以上面通过传入一个选项 colly.AllowedDomains(\u0026quot;www.baidu.com\u0026quot;) 限制只爬取域名为 www.baidu.com 的网页\n调用 c.onHTML(goquerySelector string, f HTMLCallback) 方法注册回调函数，第一个参数是类似 JQuery 的选择器，对于选择器匹配的每个元素都会执行函数 f。\n调用 c.Visit() 访问第一个页面\ncolly 爬取到页面之后，会使用 goquery 解析这个页面。然后查找注册的 HTML 回调对应元素选择器（element-selector），将 goquery.Selection 封装成一个 colly.HTMLElement 执行回调。\ncolly.HTMLElement 其实就是对 goquery.Selection 的简单封装：\n1 2 3 4 5 6 7 8 type HTMLElement struct { Name\tstring Text\tstring Request\t*Request Response\t*Response DOM\t*goquery.Selection Index\tint } HTMLElement 方法 Attr(k string)：返回当前元素的属性，上面示例中我们使用e.Attr(\u0026quot;href\u0026quot;)获取了href属性； ChildAttr(goquerySelector, attrName string)：返回goquerySelector选择的第一个子元素的attrName属性； ChildAttrs(goquerySelector, attrName string)：返回goquerySelector选择的所有子元素的attrName属性，以[]string返回； ChildText(goquerySelector string)：拼接goquerySelector选择的子元素的文本内容并返回； ChildTexts(goquerySelector string)：返回goquerySelector选择的子元素的文本内容组成的切片，以[]string返回。 ForEach(goquerySelector string, callback func(int, *HTMLElement))：对每个goquerySelector选择的子元素执行回调callback； Unmarshal(v interface{})：通过给结构体字段指定 goquerySelector 格式的 tag，可以将一个 HTMLElement 对象 Unmarshal 到一个结构体实例中。 colly 方法 NewCollector(options ...CollectorOption)：通过 options 可以设置是否异步（Async）、最大深度（Max-depth）等\nOnRequest(f RequestCallback)：请求建立时调用\nOnResponse(f ResponseCallback)：返回响应时调用\nOnHTML(goquerySelector string, f HTMLCallback)：选择器匹配 HTML 元素时调用\nOnXML(xpathQuery string, f XMLCallback)：xpath 匹配 XML 元素时调用\nOnError(f ErrorCallback)：在 HTTP 请求出错时调用\n百度小说热榜 各部分结构如下：\n每条热榜各自在一个 div.category-wrap_iQLoo 中； a 元素下 div.index_1Ew5p 是排名； 内容在 div.content_1YWBm 中； 内容中 a.title_dIF3B 是标题； 内容中两个 div.intro_1l0wp，前一个是作者，后一个是类型； 内容中 div.desc_3CTjT 是描述。 由此我们定义结构：\n1 2 3 4 5 6 7 type Hot struct { Rank\tstring `selector:\u0026#34;a \u0026gt; div.index_1Ew5p\u0026#34;` Name\tstring `selector:\u0026#34;div.content_1YWBm \u0026gt; a.title_dIF3B\u0026#34;` Author string `selector:\u0026#34;div.content_1YWBm \u0026gt; div.intro_1l0wp:nth-child(2)\u0026#34;` Type\tstring `selector:\u0026#34;div.content_1YWBm \u0026gt; div.intro_1l0wp:nth-child(3)\u0026#34;` Desc\tstring `selector:\u0026#34;div.desc_3CTjT\u0026#34;` } tag 中是 CSS 选择器语法，添加这个是为了可以直接调用HTMLElement.Unmarshal()方法填充Hot对象。\n注册回调：\n1 2 3 4 5 6 7 8 9 10 11 c.OnHTML(\u0026#34;div.category-wrap_iQLoo\u0026#34;, func(e *colly.HTMLElement) { hot := \u0026amp;Hot{} err := e.Unmarshal(hot) if err != nil { fmt.Println(\u0026#34;error:\u0026#34;, err) return } hots = append(hots, hot) }) 起点不同分类畅销榜 首先定义结构：\n1 2 3 4 5 6 7 8 9 10 type Novel struct { category\tstring\t// 分类 rank\tint\t// 排名 title\tstring\t// 书名 author\tstring\t// 作者名 words\tfloat64\t// 字数/万 tags\t[]string\t// 标签 url\tstring\t// 链接 lastUpdate\tstring\t// 上次更新时间 } 由于起点的分类、畅销榜单和书籍信息为三层，并且层与层之间的数据需要一一对应（例如玄幻小说畅销榜里的书都要对应到玄幻小说分类中）。所以使用三个 colly.Collector 对象嵌套\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 func Crawl() { novels := make([]*Novel, 0, 100) c1 := colly.NewCollector( colly.AllowedDomains(\u0026#34;www.qidian.com\u0026#34;, \u0026#34;book.qidian.com\u0026#34;), colly.Async(true),\t// 异步请求 ) // 获取所有分类链接 c1.OnHTML(\u0026#34;#classify-list a\u0026#34;, func(e *colly.HTMLElement) { category := e.Attr(\u0026#34;title\u0026#34;) href := e.Attr(\u0026#34;href\u0026#34;) if href == \u0026#34;\u0026#34; { return } c2 := c1.Clone() // 获取榜单书籍链接 c2.OnHTML(\u0026#34;div.popular-serial + div li\u0026#34;, func(e *colly.HTMLElement) { rank, _ := strconv.Atoi(strings.TrimSpace(e.Attr(\u0026#34;data-rid\u0026#34;))) // 获取到的是相对链接，转换为 url infoUrl := e.Request.AbsoluteURL(e.ChildAttr(\u0026#34;a.link, a.name\u0026#34;, \u0026#34;href\u0026#34;)) c3 := c1.Clone() // 获取书籍详细信息 c3.OnHTML(\u0026#34;div.book-info\u0026#34;, func(e *colly.HTMLElement) { title := e.ChildText(\u0026#34;h1 em\u0026#34;) author := e.ChildText(\u0026#34;h1 a.writer\u0026#34;) // 截取 5 位以后的字符串作为时间 lastUpdate := string([]rune(e.ChildText(\u0026#34;h1 span.book-update-time\u0026#34;))[5:]) tags := make([]string, 0) tags = append(tags, e.ChildText(\u0026#34;p.tag \u0026gt; a:nth-child(4)\u0026#34;), e.ChildText(\u0026#34;p.tag \u0026gt; a:nth-child(5)\u0026#34;)) // 有些书有三个标签 if tag := e.ChildText(\u0026#34;p.tag \u0026gt; a:nth-child(6)\u0026#34;); tag != \u0026#34;\u0026#34; { tags = append(tags, tag) } words, _ := strconv.ParseFloat(e.ChildText(\u0026#34;p:nth-child(4) \u0026gt; em:nth-child(1)\u0026#34;), 64) novel := \u0026amp;Novel{ category:\tcategory, rank:\trank, title:\ttitle, author:\tauthor, words:\twords, tags:\ttags, url:\tinfoUrl, lastUpdate:\tlastUpdate, } //fmt.Println(novel) novels = append(novels, novel) }) c3.Visit(infoUrl) }) c2.Visit(e.Request.AbsoluteURL(href)) // c2.Wait() // 因为是异步，所以需要等待完成 c3.Wait() }) c1.OnError(func(r *colly.Response, err error) { fmt.Println(\u0026#34;visiting \u0026#34;, r.Request.URL, \u0026#34;failed: \u0026#34;, err) }) c1.Visit(\u0026#34;https://www.qidian.com/\u0026#34;) c1.Wait() } 限速 有时候并发请求太多，网站会限制访问。这时就需要使用 LimitRule 了。说白了，LimitRule 就是限制访问速度和并发量的：\n1 2 3 4 5 6 7 type LimitRule struct { DomainRegexp\tstring DomainGlob\tstring Delay\ttime.Duration RandomDelay\ttime.Duration Parallelism\tint } 常用的就 Delay/RandomDelay/Parallism 这几个，分别表示请求与请求之间的延迟，随机延迟，和并发数。另外必须指定对哪些域名施行限制，通过 DomainRegexp 或 DomainGlob 设置，如果这两个字段都未设置 Limit() 方法会返回错误。用在上面的例子中：\n1 2 3 4 5 6 7 8 err := c.Limit(\u0026amp;colly.LimitRule{ DomainRegexp:\t`unsplash\\.com`, RandomDelay:\t500 * time.Millisecond, Parallelism:\t12, }) if err != nil { log.Fatal(err) } 设置针对 unsplash.com 这个域名，请求与请求之间的随机最大延迟 500ms，最多同时并发 12 个请求。\n设置超时 有时候网速较慢，colly 中使用的 http.Client 有默认超时机制，我们可以通过colly.WithTransport() 选项改写：\n1 2 3 4 5 6 7 8 9 10 11 c.WithTransport(\u0026amp;http.Transport{ Proxy: http.ProxyFromEnvironment, DialContext: (\u0026amp;net.Dialer{ Timeout:\t30 * time.Second, KeepAlive: 30 * time.Second, }).DialContext, MaxIdleConns:\t100, IdleConnTimeout:\t90 * time.Second, TLSHandshakeTimeout:\t10 * time.Second, ExpectContinueTimeout:\t1 * time.Second, }) 扩展 colly 在子包 extension 中提供了一些扩展特性，最最常用的就是随机 User-Agent 了。通常网站会通过 User-Agent 识别请求是否是浏览器发出的，爬虫一般会设置这个 Header 把自己伪装成浏览器。使用也比较简单：\n1 2 3 4 5 6 import \u0026#34;github.com/gocolly/colly/v2/extensions\u0026#34; func main() { c := colly.NewCollector() extensions.RandomUserAgent(c) } 随机 User-Agent 实现也很简单，就是从一些预先定义好的 User-Agent 数组中随机一个设置到 Header 中：\n1 2 3 4 5 func RandomUserAgent(c *colly.Collector) { c.OnRequest(func(r *colly.Request) { r.Headers.Set(\u0026#34;User-Agent\u0026#34;, uaGens[rand.Intn(len(uaGens))]()) }) } 实现自己的扩展也不难，例如我们每次请求时需要设置一个特定的 Header，扩展可以这么写：\n1 2 3 4 5 func MyHeader(c *colly.Collector) { c.OnRequest(func(r *colly.Request) { r.Headers.Set(\u0026#34;My-Header\u0026#34;, \u0026#34;dj\u0026#34;) }) } 用 Collector 对象调用 MyHeader() 函数即可：\n1 MyHeader(c) 参考 Go 每日一库 GitHub Go 每日一库之 colly ","permalink":"https://note-site.pages.dev/posts/golang/daily-lib/colly/","summary":"简介 colly 是用 Go 语言编写的功能强大的爬虫框架。它提供简洁的 API，拥有强劲的性能，可以自动处理 cookie\u0026amp;session，还有提供灵活","title":"Colly"},{"content":"pie 封装了对切片和 map 的常用操作,能满足工作中的大部分需求。比如计算切片的交集、差集；对切片中元素按条件过滤的 Filter 函数；对切片中元素进行数据转换的 Each、Map 函数等。\npie v2 版本需要 Go 1.18+。Go1.17 及以下版本需要使用 v1 版本。\n使用示例 1 2 3 4 5 6 7 8 9 func TestPie(t *testing.T) { name := pie.Of([]string{\u0026#34;Bob\u0026#34;, \u0026#34;Sally\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;Jane\u0026#34;}). FilterNot(func(name string) bool { return strings.HasPrefix(name, \u0026#34;J\u0026#34;) }). Map(strings.ToUpper). Last() fmt.Println(name) // \u0026#34;SALLY\u0026#34; } pie 包的目标 类型安全：无论是在 v1 版本还是 v2 版本的泛型中，都对类型做了限制，所以不会遇到运行时类型错误。 高性能：该库需要跟原生的 Go 实现一样快，否则该库封装就没有意义。 Nil 安全：该库的所有函数都能接收 nil 参数，并将其视为空切片，而不会引起 panic。 对原切片无副作用：所有的函数对传入的切片参数都不会做修改。 pie 包支持的功能 切片中的元素是否全部或任意一个满足指定的条件。\nAll 函数：判断切片中的元素是否都满足指定的条件。 Any 函数：判断切片中的元素只要有 1 个满足指定条件即可。 对切片元素进行排序功能。\nAreSorted 函数：判断切片是否是有序的 Sort 函数：对切片元素进行排序。 SortStableUsing 函数：使用指定的条件对切片进行排序，并且具有稳定性。 SortUsing 函数 对切片中的元素去重。\n判断切片中的元素是否不重复的 AreUnique 函数、去重函数 Unique 对切片进行前、后截取。\nBottom 函数：取切片后 n 个元素 Top 函数：取切片前 n 个元素 DropTop 函数：丢掉切片的前 n 个元素，并返回剩余的元素切片 两个或多个切片之间的集合运算\nDiff 函数：计算两个切片中的差集 Intersect 函数：计算两个或多个切片的交集 1 2 3 4 5 6 7 8 9 func TestDiff(t *testing.T) { added, removed := pie.Diff([]string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}, []string{\u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;}) fmt.Println(added, removed) // [d] [a] } func TestIntersect(t *testing.T) { ss2 := pie.Intersect([]string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}, []string{\u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;}) fmt.Println(ss2) // [c b] } 切片元素进行算数运算功能（只针对 Integer 和 float 类型的切片有效）。 Max 函数：返回切片中的最大元素 Min 函数：返回切片中的最小元素 Product 函数：对切片所有元素进行乘积运算 Sum 函数：对切片中所有元素进行求和运算 Average 函数：求所有元素的平均值 对切片中的元素进行数据转换功能：Each、Map、Filter、Flat、Reducer 1 2 3 4 5 6 func TestEach(t *testing.T) { pie.Of([]string{\u0026#34;Bob\u0026#34;, \u0026#34;Sally\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;Jane\u0026#34;}). Each(func(s string) { fmt.Println(s) }) } 针对 map 的操作： Keys 函数：获取 map 的所有键 Values 函数：获取 map 的所有值 ","permalink":"https://note-site.pages.dev/posts/golang/daily-lib/pie/","summary":"pie 封装了对切片和 map 的常用操作,能满足工作中的大部分需求。比如计算切片的交集、差集；对切片中元素按条件过滤的 Filter 函数；对切片中元素进行数据转换的","title":"Pie"},{"content":"介绍 singleflight 来源于准官方库 golang.org/x/sync/singleflight，能够抑制对下游的多次重复请求。主要提供了以下三个方法：\n1 2 3 4 5 6 7 8 9 10 11 // Do(): 相同的 key，fn 同时只会执行一次，返回执行的结果给 fn 执行期间，所有使用该 key 的调用 // v: fn 返回的数据 // err: fn 返回的err // shared: 表示返回数据是调用 fn 得到的还是其他相同 key 调用返回的 func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) // DoChan(): 类似 Do() 方法，以 chan 返回结果 func (g *Group) DoChan(key string, fn func() (interface{}, error)) \u0026lt;-chan Result // Forget(): 失效 key，后续对此 key 的调用将执行 fn，而不是等待前面的调用完成 func (g *Group) Forget(key string) 使用方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/sync/singleflight\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) type Result string func find(ctx context.Context, query string) (Result, error) { return Result(fmt.Sprintf(\u0026#34;result for %q\u0026#34;, query)), nil } func main() { var g singleflight.Group const n = 5 waited := int32(n) done := make(chan struct{}) key := \u0026#34;https://weibo.com/1227368500/H3GIgngon\u0026#34; for i := 0; i \u0026lt; n; i++ { go func(j int) { v, _, shared := g.Do(key, func() (interface{}, error) { ret, err := find(context.Background(), key) return ret, err }) if atomic.AddInt32(\u0026amp;waited, -1) == 0 { close(done) } fmt.Printf(\u0026#34;index: %d, val: %v, shared: %v\\n\u0026#34;, j, v, shared) }(i) } select { case \u0026lt;-done: case \u0026lt;-time.After(time.Second): fmt.Println(\u0026#34;Do hangs\u0026#34;) } } 输出结果如下：\n1 2 3 4 5 index: 1, val: result for \u0026#34;https://weibo.com/1227368500/H3GIgngon\u0026#34;, shared: true index: 2, val: result for \u0026#34;https://weibo.com/1227368500/H3GIgngon\u0026#34;, shared: true index: 4, val: result for \u0026#34;https://weibo.com/1227368500/H3GIgngon\u0026#34;, shared: true index: 3, val: result for \u0026#34;https://weibo.com/1227368500/H3GIgngon\u0026#34;, shared: true index: 0, val: result for \u0026#34;https://weibo.com/1227368500/H3GIgngon\u0026#34;, shared: true 注意事项 比较常见的业务场景是直接使用 singleflight.Do 方法，这在极端情况下可能会导致参与竞争的 goroutine 全部阻塞。例如从数据库读取数据并写入缓存中这个场景，如果 singleflight.Do 方法内部调用的函数因为某种原因阻塞住了，那么会导致所有等待缓存数据的 goroutine 全部阻塞。换言之，singleflight 是以牺牲成功率的代价控制了并发量。\n那么该如何解决以上问题呢？\n作为 Do() 的替代函数，singleflight 提供了 DoChan()。两者实现上完全一样，不同的是，DoChan() 通过 channel 返回结果，因此可以使用 select 语句实现超时控制。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 var g singleflight.Group var wg sync.WaitGroup\t// 通过wg控制主进程在其它goroutine结束后再结束 const n = 5 key := \u0026#34;https://weibo.com/1227368500/H3GIgngon\u0026#34; for i := 0; i \u0026lt; n; i++ { go func(j int) { wg.Add(1) defer wg.Done() ch := g.DoChan(key, func() (interface{}, error) { ret, err := find(context.Background(), key) return ret, err }) timeout := time.After(500 * time.Millisecond) var ret singleflight.Result select { case ret = \u0026lt;-ch: fmt.Printf(\u0026#34;index: %d, val: %v, shared: %v\\n\u0026#34;, j, ret.Val, ret.Shared) case \u0026lt;-timeout: fmt.Printf(\u0026#34;%d: timeout\\n\u0026#34;, j) return } }(i) } wg.Wait() 输出结果与 Do 示例类似。\n在一些对可用性要求极高的场景下，往往需要一定的请求饱和度来保证业务的最终成功率。一次请求还是多次请求，对于下游服务而言并没有太大区别，此时使用 singleflight 只是为了降低请求的数量级，那么可以使用 Forget() 提高下游请求的并发：\n1 2 3 4 5 6 7 8 9 v, _, shared := g.Do(key, func() (interface{}, error) { go func() { time.Sleep(10 * time.Millisecond) fmt.Printf(\u0026#34;Deleting key: %v\\n\u0026#34;, key) g.Forget(key) }() ret, err := find(context.Background(), key) return ret, err }) 当有一个并发请求超过 10ms，那么将会有第二个请求发起，此时只有 10ms 内的请求最多发起一次请求，即最大并发：100 QPS。单次请求失败的影响大大降低。\n当然，如果单次的失败无法容忍，在高并发的场景下更好的处理方案是：\n放弃使用同步请求，牺牲数据更新的实时性 “缓存” 存储准实时的数据 + “异步更新” 数据到缓存 内部实现 见 singleflight内部实现\n参考 sync.singleflight 到底怎么用才对？\n","permalink":"https://note-site.pages.dev/posts/golang/daily-lib/singleflight/","summary":"介绍 singleflight 来源于准官方库 golang.org/x/sync/singleflight，能够抑制对下游的多次重复请求。主要提供了以下三个方法： 1 2","title":"Singleflight"}]